{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8f418d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor as SklearnGBR, AdaBoostRegressor as SklearnAdaBoost\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee804d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionStump:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.feature_index: int | None = None\n",
    "        self.threshold: float | None = None\n",
    "        self.left_value: float | None = None\n",
    "        self.right_value: float | None = None\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray, sample_weights: np.ndarray | None = None):\n",
    "        if sample_weights is None:\n",
    "            sample_weights = np.ones_like(y, dtype=float)\n",
    "        m, n = X.shape\n",
    "        best_loss = np.inf\n",
    "\n",
    "        for feature in range(n):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for thr in thresholds:\n",
    "                left = X[:, feature] <= thr\n",
    "                right = ~left\n",
    "                if not left.any() or not right.any():\n",
    "                    continue\n",
    "                lw = sample_weights[left]\n",
    "                rw = sample_weights[right]\n",
    "\n",
    "                lv = np.average(y[left], weights=lw)\n",
    "                rv = np.average(y[right], weights=rw)\n",
    "\n",
    "                pred = np.where(left, lv, rv)\n",
    "                loss = np.average((y - pred) ** 2, weights=sample_weights)\n",
    "                if loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    self.feature_index = feature\n",
    "                    self.threshold = thr\n",
    "                    self.left_value = lv\n",
    "                    self.right_value = rv\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        feat = X[:, self.feature_index]\n",
    "        return np.where(feat <= self.threshold, self.left_value, self.right_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "487c4820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoostingRegressor:\n",
    "    def __init__(self, n_estimators: int = 100, learning_rate: float = 0.1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.trees: list[DecisionStump] = []\n",
    "        self.init_value: float | None = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        self.init_value = np.mean(y)\n",
    "        y_pred = np.full_like(y, self.init_value, dtype=float)\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            residual = y - y_pred\n",
    "            stump = DecisionStump()\n",
    "            stump.fit(X, residual)\n",
    "            update = stump.predict(X)\n",
    "            y_pred += self.learning_rate * update\n",
    "            self.trees.append(stump)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X)\n",
    "        y_pred = np.full(X.shape[0], self.init_value, dtype=float)\n",
    "        for stump in self.trees:\n",
    "            y_pred += self.learning_rate * stump.predict(X)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8789e0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KDE:\n",
    "    def __init__(self, bandwidth: float = 1.0):\n",
    "        self.bandwidth = bandwidth\n",
    "        self.X_train: np.ndarray | None = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.X_train = np.asarray(X)\n",
    "\n",
    "    def evaluate(self, X):\n",
    "        X = np.asarray(X).reshape(-1, 1)\n",
    "        n = self.X_train.shape[0]\n",
    "        const = 1 / (self.bandwidth * np.sqrt(2 * np.pi) * n)\n",
    "        diffs = (X - self.X_train) / self.bandwidth\n",
    "        densities = const * np.sum(np.exp(-0.5 * diffs ** 2), axis=1)\n",
    "        return densities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d2f77bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAdaBoostRegressor:\n",
    "    \"\"\"Простая реализация AdaBoost.R2 с пнями в качестве базовых моделей.\"\"\"\n",
    "\n",
    "    def __init__(self, n_estimators: int = 50):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.models: list[DecisionStump] = []\n",
    "        self.alphas: list[float] = []  # alpha_t = ln(1/beta_t)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        n = len(y)\n",
    "        w = np.full(n, 1 / n)\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            stump = DecisionStump()\n",
    "            stump.fit(X, y, sample_weights=w)\n",
    "            pred = stump.predict(X)\n",
    "\n",
    "            error = np.abs(y - pred)\n",
    "            max_err = error.max()\n",
    "            if max_err == 0:\n",
    "                beta = 0\n",
    "            else:\n",
    "                error_norm = np.average(error / max_err, weights=w)\n",
    "                # если модель не лучше случайной, прерываемся\n",
    "                if error_norm >= 0.5:\n",
    "                    break\n",
    "                beta = error_norm / (1 - error_norm)\n",
    "\n",
    "            # веса и alpha\n",
    "            alpha = np.log(1 / (beta + 1e-10))\n",
    "            self.models.append(stump)\n",
    "            self.alphas.append(alpha)\n",
    "\n",
    "            # обновление весов\n",
    "            w *= beta ** (1 - error / (max_err + 1e-12))\n",
    "            w /= w.sum()\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X)\n",
    "        preds = np.zeros(X.shape[0])\n",
    "        total_alpha = np.sum(self.alphas)\n",
    "        for stump, alpha in zip(self.models, self.alphas):\n",
    "            preds += alpha * stump.predict(X)\n",
    "        return preds / total_alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5287247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"prices_train.csv\")\n",
    "test_df = pd.read_csv(\"prices_test.csv\")\n",
    "\n",
    "train_df = train_df.drop(columns=[\"Unnamed: 0\"])\n",
    "test_df = test_df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "y_train = train_df[\"Y house price of unit area\"]\n",
    "X_train = train_df.drop(columns=[\"Y house price of unit area\"])\n",
    "\n",
    "combined = pd.concat([X_train, test_df], axis=0)\n",
    "combined_filled = combined.fillna(combined.mean(numeric_only=True)).fillna(0)\n",
    "\n",
    "X_train_filled = combined_filled.iloc[: len(X_train)]\n",
    "X_test_filled = combined_filled.iloc[len(X_train) :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fed86a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE custom: 54.71336785891531\n",
      "MSE sklearn: 54.71336785891531\n"
     ]
    }
   ],
   "source": [
    "my_gb = GradientBoostingRegressor(n_estimators=50, learning_rate=0.1)\n",
    "my_gb.fit(X_train_filled, y_train)\n",
    "print(\"MSE custom:\", mean_squared_error(y_train, my_gb.predict(X_train_filled)))\n",
    "\n",
    "sk_gb = SklearnGBR(n_estimators=50, learning_rate=0.1, max_depth=1)\n",
    "sk_gb.fit(X_train_filled, y_train)\n",
    "print(\"MSE sklearn:\", mean_squared_error(y_train, sk_gb.predict(X_train_filled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a305bd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== KDE =====\n",
      "Custom densities: [0.03348561 0.01329155 0.02025072 0.01244522 0.02434462]\n",
      "Sklearn densities: [0.03348561 0.01329155 0.02025072 0.01244522 0.02434462]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== KDE =====\")\n",
    "my_kde = KDE(bandwidth=3)\n",
    "my_kde.fit(y_train)\n",
    "print(\"Custom densities:\", my_kde.evaluate(y_train[:5]))\n",
    "\n",
    "sk_kde = KernelDensity(bandwidth=3)\n",
    "sk_kde.fit(y_train.values.reshape(-1, 1))\n",
    "print(\"Sklearn densities:\", np.exp(sk_kde.score_samples(y_train[:5].values.reshape(-1, 1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb21ac57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== AdaBoost.R2 =====\n",
      "MSE custom: 139.36755465078411\n",
      "MSE sklearn: 40.17101510100741\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"\\n===== AdaBoost.R2 =====\")\n",
    "my_ab = MyAdaBoostRegressor(n_estimators=40)\n",
    "my_ab.fit(X_train_filled, y_train)\n",
    "print(\"MSE custom:\", mean_squared_error(y_train, my_ab.predict(X_train_filled)))\n",
    "\n",
    "sk_ab = SklearnAdaBoost(n_estimators=40)\n",
    "sk_ab.fit(X_train_filled, y_train)\n",
    "print(\"MSE sklearn:\", mean_squared_error(y_train, sk_ab.predict(X_train_filled)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
